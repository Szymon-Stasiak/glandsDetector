{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Glands Segmentator #\n",
   "id": "895e892f6c86a09b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this file, I use two models that I created to successfully perform gland segmentation. The process forms a pipeline where an input image is provided for segmentation, and the output is an image with the segmented glands.",
   "id": "1c7ea94307d99578"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Procesing of big images #",
   "id": "8f795e928715d8a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Imports:",
   "id": "a046b5b769ac14ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T18:18:12.539115Z",
     "start_time": "2025-05-18T18:18:09.824082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import tifffile"
   ],
   "id": "8a12f55e89e19ab",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading models:",
   "id": "c30589ddcd38d44f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T22:04:28.933132Z",
     "start_time": "2025-05-18T22:04:28.928323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import unet_core \n",
    "print(unet_core.__file__)  # Pokazuje lokalizacjÄ™ faktycznego pliku\n",
    "dir(unet_core)         \n",
    "\n",
    "# Czy zawiera 'UNET'?\n"
   ],
   "id": "3326263a9ee24ce2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stszy\\miniconda3\\Lib\\site-packages\\unet_core\\__init__.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['UNet',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'dataset',\n",
       " 'model',\n",
       " 'utils']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T21:51:44.479609Z",
     "start_time": "2025-05-18T21:51:44.476564Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "59e2caeb76cd4209",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T22:09:14.013200Z",
     "start_time": "2025-05-18T22:09:13.864883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "detectionModel = YOLO(\"../model/saved_models/Glands_Finder_Augumented_Data_best.pt\")\n",
    "from unet_core.unet_interface import UNET\n",
    "modelUNET=UNET._model(name=\"GlandsFInder\")"
   ],
   "id": "859920d19ffbab12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with name GlandsFInder doesn't exist\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Helper function:",
   "id": "d3b1128b58bed4a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def tile_image(image, tile_size, overlap):\n",
    "    tiles = []\n",
    "    positions = []\n",
    "    h, w = image.shape[:2]\n",
    "    stride = tile_size - overlap\n",
    "\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            x_end = min(x + tile_size, w)\n",
    "            y_end = min(y + tile_size, h)\n",
    "            tile = image[y:y_end, x:x_end]\n",
    "            tiles.append(tile)\n",
    "            positions.append((x, y))\n",
    "    return tiles, positions\n",
    "\n",
    "\n",
    "def detect_on_tiles(tiles, positions, tile_size,model):\n",
    "    all_detections = []\n",
    "    for tile, (x_offset, y_offset) in zip(tiles, positions):\n",
    "        results = model(tile, conf=0.6)[0]\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            x1 += x_offset\n",
    "            x2 += x_offset\n",
    "            y1 += y_offset\n",
    "            y2 += y_offset\n",
    "            conf = float(box.conf)\n",
    "            cls = int(box.cls)\n",
    "            all_detections.append((x1, y1, x2, y2, conf, cls))\n",
    "    return all_detections\n",
    "\n",
    "\n",
    "def draw_detections(image, detections, class_names):\n",
    "    annotated = image.copy()\n",
    "    for x1, y1, x2, y2, conf, cls in detections:\n",
    "        cv2.rectangle(annotated, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        label = f\"{class_names[cls]} {conf:.2f}\"\n",
    "        cv2.putText(annotated, label, (int(x1), int(y1) - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    return annotated\n",
    "\n",
    "\n",
    "def merge_overlapping_boxes_hierarchical(\n",
    "        detections,\n",
    "        iou_threshold=0.5,\n",
    "        containment_thresh=0.8,\n",
    "        center_inclusion=False,\n",
    "        linkage='complete'\n",
    "):\n",
    "    def iou(boxA, boxB):\n",
    "        xA = max(boxA[0], boxB[0])\n",
    "        yA = max(boxA[1], boxB[1])\n",
    "        xB = min(boxA[2], boxB[2])\n",
    "        yB = min(boxA[3], boxB[3])\n",
    "        interW = max(0, xB - xA)\n",
    "        interH = max(0, yB - yA)\n",
    "        interArea = interW * interH\n",
    "        if interArea == 0:\n",
    "            return 0.0\n",
    "        areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "        areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "        return interArea / float(areaA + areaB - interArea)\n",
    "\n",
    "    def containment_ratio(inner, outer):\n",
    "        xA = max(inner[0], outer[0])\n",
    "        yA = max(inner[1], outer[1])\n",
    "        xB = min(inner[2], outer[2])\n",
    "        yB = min(inner[3], outer[3])\n",
    "        interW = max(0, xB - xA)\n",
    "        interH = max(0, yB - yA)\n",
    "        interArea = interW * interH\n",
    "        areaInner = (inner[2] - inner[0]) * (inner[3] - inner[1])\n",
    "        if areaInner == 0:\n",
    "            return 0.0\n",
    "        return interArea / areaInner\n",
    "\n",
    "    def center_in_box(box, center):\n",
    "        x, y = center\n",
    "        return box[0] <= x <= box[2] and box[1] <= y <= box[3]\n",
    "\n",
    "    merged = []\n",
    "    by_class = {}\n",
    "    for det in detections:\n",
    "        by_class.setdefault(det[5], []).append(det)\n",
    "\n",
    "    for cls, dets in by_class.items():\n",
    "        n = len(dets)\n",
    "        if n == 0:\n",
    "            continue\n",
    "        boxes = np.array([d[:4] for d in dets])\n",
    "        dist = np.zeros((n, n), dtype=float)\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                val = iou(boxes[i], boxes[j])\n",
    "                d = 1.0 - val\n",
    "                dist[i, j] = dist[j, i] = d\n",
    "\n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            affinity='precomputed',\n",
    "            linkage=linkage,\n",
    "            distance_threshold=1.0 - iou_threshold\n",
    "        )\n",
    "        labels = clustering.fit_predict(dist)\n",
    "\n",
    "        for label in np.unique(labels):\n",
    "            group = [dets[i] for i in range(n) if labels[i] == label]\n",
    "            filtered = []\n",
    "            for det in group:\n",
    "                keep = True\n",
    "                if containment_thresh:\n",
    "                    for other in group:\n",
    "                        if det is other:\n",
    "                            continue\n",
    "                        cont = containment_ratio(det[:4], other[:4])\n",
    "                        if cont < containment_thresh and containment_ratio(other[:4], det[:4]) < containment_thresh:\n",
    "                            keep = False\n",
    "                            break\n",
    "                if center_inclusion:\n",
    "                    center = ((det[0] + det[2]) / 2, (det[1] + det[3]) / 2)\n",
    "                    in_any = any(center_in_box(other[:4], center) for other in group if other is not det)\n",
    "                    keep = keep and in_any\n",
    "                if keep:\n",
    "                    filtered.append(det)\n",
    "            if not filtered:\n",
    "                filtered = group\n",
    "\n",
    "            xs = [d[0] for d in filtered] + [d[2] for d in filtered]\n",
    "            ys = [d[1] for d in filtered] + [d[3] for d in filtered]\n",
    "            max_conf = max(d[4] for d in filtered)\n",
    "            merged.append((min(xs), min(ys), max(xs), max(ys), max_conf, cls))\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "def draw_detections_varied_colors(image, detections, class_names, thickness=2, font_scale=0.5):\n",
    "    annotated = image.copy()\n",
    "    random.seed(42)\n",
    "\n",
    "    for idx, det in enumerate(detections):\n",
    "        x1, y1, x2, y2, conf, cls_id = det\n",
    "\n",
    "        color = tuple(int(c) for c in np.random.randint(0, 256, size=3))\n",
    "\n",
    "        label = f\"{class_names[int(cls_id)]} {conf:.2f}\"\n",
    "\n",
    "        cv2.rectangle(annotated, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness)\n",
    "        text_y = int(y1) - 5 if y1 > 10 else int(y1) + 15\n",
    "        cv2.putText(\n",
    "            annotated,\n",
    "            label,\n",
    "            (int(x1), text_y),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            font_scale,\n",
    "            color,\n",
    "            thickness=1,\n",
    "            lineType=cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "    return annotated"
   ],
   "id": "7af23a9e74aed887"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "image_path = \"../preprocessedData/tissue_regions/1M01/tissue_region_0.tiff\"\n",
    "image = tifffile.imread(image_path)\n",
    "if image.ndim == 3 and image.shape[2] > 3:\n",
    "    image = image[:, :, :3]\n",
    "\n",
    "if image.ndim == 2:\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "tile_size = 2048 \n",
    "overlap = 1024\n",
    "tiles, positions = tile_image(image, tile_size, overlap)\n",
    "\n",
    "detections = detect_on_tiles(tiles, positions, tile_size , detectionModel)\n",
    "\n",
    "class_names = detectionModel.names\n",
    "\n",
    "annotated = draw_detections(image, detections, class_names)\n",
    "\n",
    "cv2.imwrite(\"wynik_z_detections.png\", annotated)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(cv2.cvtColor(tiles[3], cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Tile 0\")\n",
    "plt.show()\n",
    "\n",
    "test_tile = tiles[3]\n",
    "result = detectionModel(test_tile, conf=0.3)[0]\n",
    "print(\"Wykryto bboxÃ³w:\", len(result.boxes))\n",
    "\n",
    "result.show()\n",
    "import random\n",
    "\n",
    "annotated = draw_detections_varied_colors(image, detections, class_names)\n",
    "cv2.imwrite(\"wynik_rozrozne_kolory.png\", annotated)"
   ],
   "id": "89525eff010e45f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
